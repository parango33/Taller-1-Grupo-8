# -*- coding: utf-8 -*-
"""Sistema_de_recomendación_Last_1K_FM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HsqIwH3yLtEe1Q3PJdKDyJf8nLsNL6JX
"""

#pip install wget

#import wget

#site_url = 'http://mtg.upf.edu/static/datasets/last.fm/lastfm-dataset-1K.tar.gz'
#datos = wget.download(site_url)
#print(file_name)

#ls

#import tarfile
#file = tarfile.open(datos)

# print file names
#print(file.getnames())

#file.extractall('./')

#file.close()

#ls


"""import all required libraries"""

import os
import numpy as np
import pandas as pd
from surprise import Reader
from surprise import Dataset
from surprise.model_selection import train_test_split
#from sklearn.model_selection import train_test_split
from surprise import KNNBasic
from surprise import accuracy
import random

#Para garantizar reproducibilidad en resultados
seed = 10
random.seed(seed)
np.random.seed(seed)

# Load the data like we did before

#CARGAR DATOS

import wget

site_url = 'http://mtg.upf.edu/static/datasets/last.fm/lastfm-dataset-1K.tar.gz'
wget.download(site_url)
#print(file_name)

if not os.path.exists('lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv') :
  raise ValueError('Archivo no encontrado')
else:
  print("¡Interacciones cargadas!")
  

user_data = pd.read_table('lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv',
                          header = None, nrows = 2e7,
                          names = ['users', 'Timestamp', 'Artist Id', 'Artist Name', 'Track Id','Track Name'],
                          usecols = ['users', 'Artist Name', 'Track Name'])


if not os.path.exists('userid-profile.tsv') :
  raise ValueError('Archivo no encontrado')
else:
  print("¡Usuarios cargado!s")

user_profiles = pd.read_table('userid-profile.tsv',
                          header = None,
                          names = ['users', 'gender', 'age', 'country', 'signup'],
                          usecols = ['users', 'country'])



print("Read")                          

user_data.head()

user_data.describe()

user_profiles.head()

"""Filtering to Only Popular Artists"""

print("Agrupando usuarios por pais...")
Data=pd.merge(user_data,user_profiles[['users','country']],on='users',how='left')
Data.head()

#users_df.country.hist()

#users_df.sort_values(by='media', ascending=False).head(20) # top 20 items en calificaciones
users_by_Country=user_profiles.groupby('country')['users'].agg({'count'})
users_by_Country.sort_values(by='count',ascending=False).head(20)

"""El mayor numero de usuario se encuentra en Usa, por eso vamos a filtrar por ese Country

---

Este data frame artist_by_user, es la cuenta de las escuchas de cada usuario de cada artista.
"""
print("El mayor numero de usuario se encuentra en Usa, por eso vamos a filtrar por ese Country...")

print("Creando dataframe artist_by_user: La cuenta de las escuchas de cada usuario de cada artista.")

artist_by_user=Data.groupby(['users','Artist Name','country'])['Track Name'].agg({'count'})
artist_by_user=artist_by_user.reset_index(level=['users','Artist Name','country'])
artist_by_user

"""Este frame tiene el promedio de reproducciones por artita que tiene un usuario."""

print("Creando dataframe promedio de reproducciones por artita que tiene un usuario.")


user_listening=artist_by_user.groupby('users')['count'].agg('mean')
user_listening=user_listening.to_frame()
user_listening=user_listening.reset_index(level=['users'])
user_listening

items_ratings=pd.merge(artist_by_user,user_listening,on='users',how='left')
items_ratings.rename(columns={'count_x':'count','count_y': 'media'},inplace=True)

"""Aqui hacemos el merge entre los dos frames anteriores para poder relacionar el número de escuchas con el promedio. Cuenta/promedio= Rating. Cuando este valor es mayor a 1 entonces podemos decir que es un artista favorito del usario, y entre más cercano a cero menos le gusta porque lo ha escuchado menos."""

print("Haciendo merge entre los dos frames anteriores para poder relacionar el número de escuchas con el promedio. Cuenta/promedio= Rating. Cuando este valor es mayor a 1 entonces podemos decir que es un artista favorito del usario, y entre más cercano a cero menos le gusta porque lo ha escuchado menos.")


items_ratings=pd.DataFrame(items_ratings)
items_ratings['Rating']=items_ratings['count']/items_ratings['media']
items_ratings

"""Filtrar por USA"""

Usa=items_ratings[(items_ratings['country']=='United States')]

print("Ratings USA: ")
print(Usa.head())

Usa_artists=Usa[['Artist Name','count']].groupby(['Artist Name']).sum()
#Usa_artists
Usa_artists.sort_values(by='count',ascending=False)

"""Picking a threshold for popular artists

> Bloc con sangría


"""

Usa_artists['count'].quantile(np.arange(.9, 1, .01))

"""Seleccionamos la lista de de artistas que estan en el ultimo percentil de popularidad de reporducciones"""

popular_artists=Usa_artists[Usa_artists['count']>=80]
popular_artists.reset_index(level=['Artist Name'],inplace=True)
popular_artists=popular_artists['Artist Name'].to_list()

print('Lista artistas en el ultimo percentil de popularidad')
print(popular_artists)



Usa_top=Usa[Usa['Artist Name'].isin(popular_artists)]
Usa_top

"""Implementación del Modelo"""

print('Empezando ejecución del modelo')

top_rating=Usa_top['Rating'].max()

reader = Reader( rating_scale = ( 0, top_rating ) )

surprise_dataset = Dataset.load_from_df( Usa_top[ [ 'users', 'Artist Name', 'Rating' ] ].sample(frac=1), reader )

train_set, test_set=  train_test_split(surprise_dataset, test_size=.2)

# se crea un modelo knnbasic item-item con similitud coseno 
sim_options = {'name': 'pearson',
               'user_based': False  # calcule similitud item-item
               }
algo = KNNBasic(k=20, min_k=2, sim_options=sim_options)

test_set[1]

algo.fit(trainset=train_set)

print('Modelo ejecutado')

print("prediccion para user_000544: ")
print(algo.predict('user_000544','Langhorne Slim'))

"""Prueba con el dato 1 da una buena similitud"""

test_predictions=algo.test(test_set)

test_predictions[0:5]

print("Prueba con dato 1:")
print("accuracy: ",accuracy.rmse( test_predictions, verbose = True ))

"""Iteración de vecinos para evaluar calidad del Modelo"""


print("Empezando iteracion de vecinos...")


n=range(10,40)
a=[]
for v in n:
  
  # se crea un modelo knnbasic item-item con similitud coseno 
  sim_options_uu = {'name': 'pearson',
                'user_based': True  # calcule similitud item-item
                }
  algo_uu = KNNBasic(k=v, min_k=2, sim_options=sim_options_uu)

  #Se le pasa la matriz de utilidad al algoritmo 
  algo_uu.fit(trainset=train_set)

  test_predictions_uu=algo_uu.test(test_set)
  a.append([accuracy.rmse( test_predictions_uu, verbose = True ),v])
Results_pearson=pd.DataFrame(a,columns=['RMSE','Neighbors'])
Results_pearson

Results_pearson.plot.scatter(x='Neighbors',y='RMSE')

"""A partir de 20 vecinos los valores RMSE no tiene un cambion significativos"""

n=range(10,40)
a=[]
for v in n:
  
  # se crea un modelo knnbasic item-item con similitud coseno 
  sim_options_uu = {'name': 'cosine',
                'user_based': True  # calcule similitud item-item
                }
  algo_uu = KNNBasic(k=v, min_k=2, sim_options=sim_options_uu)

  #Se le pasa la matriz de utilidad al algoritmo 
  algo_uu.fit(trainset=train_set)

  test_predictions_uu=algo_uu.test(test_set)
  a.append([accuracy.rmse( test_predictions_uu, verbose = True ),v])
Results_cosine=pd.DataFrame(a,columns=['RMSE','Neighbors'])
Results_cosine

Results_cosine.plot.scatter(x='Neighbors',y='RMSE')

"""Item Item"""

n=range(10,20)
a=[]
for v in n:
  
  # se crea un modelo knnbasic item-item con similitud coseno 
  sim_options_uu = {'name': 'pearson',
                'user_based': False  # calcule similitud item-item
                }
  algo_uu = KNNBasic(k=v, min_k=2, sim_options=sim_options_uu)

  #Se le pasa la matriz de utilidad al algoritmo 
  algo_uu.fit(trainset=train_set)

  test_predictions_uu=algo_uu.test(test_set)
  a.append([accuracy.rmse( test_predictions_uu, verbose = True ),v])
Results_pearson_item=pd.DataFrame(a,columns=['RMSE','Neighbors'])
Results_pearson_item

Results_pearson_item.plot.scatter(x='Neighbors',y='RMSE')

n=range(10,25)
a=[]
for v in n:
  
  # se crea un modelo knnbasic item-item con similitud coseno 
  sim_options_uu = {'name': 'cosine',
                'user_based': False  # calcule similitud item-item
                }
  algo_uu = KNNBasic(k=v, min_k=2, sim_options=sim_options_uu)

  #Se le pasa la matriz de utilidad al algoritmo 
  algo_uu.fit(trainset=train_set)

  test_predictions_uu=algo_uu.test(test_set)
  a.append([accuracy.rmse( test_predictions_uu, verbose = True ),v])
Results_cosine_item=pd.DataFrame(a,columns=['RMSE','Neighbors'])
Results_cosine_item

Results_cosine_item.plot.scatter(x='Neighbors',y='RMSE')







"""Implemeting the Nearest Neighbor Model"""

wide_artist_data = usa_data.pivot(index = 'Artist Name', columns = 'users', values = 'plays').fillna(0)
wide_artist_data_sparse = csr_matrix(wide_artist_data.values)

"""Fitting the Model Cosine"""

from sklearn.neighbors import NearestNeighbors

model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute')
model_knn.fit(wide_artist_data_sparse)

"""Making Recommendations"""

query_index = np.random.choice(wide_data.shape[0])
print (query_index)
distances, indices = model_knn.kneighbors(wide_artist_data.iloc[query_index, :].reshape(1, -1), n_neighbors = 6)



for i in range(0, len(distances.flatten())):
    if i == 0:
        print ('Recommendations for {0}:\n'.format(wide_artist_data.index[query_index]))
    else:
        print ('{0}: {1}, with distance of {2}:'.format(i, wide_artist_data.index[indices.flatten()[i]], distances.flatten()[i]))

"""Binary Play Count Data"""

wide_artist_data_zero_one = wide_artist_data.apply(np.sign)
wide_artist_data_zero_one_sparse = csr_matrix(wide_artist_data_zero_one.values)

model_nn_binary = NearestNeighbors(metric='cosine', algorithm='brute')
model_nn_binary.fit(wide_artist_data_zero_one_sparse)

query_index = np.random.choice(wide_artist_data_zero_one.shape[0])
#print query_index
distances, indices = model_nn_binary.kneighbors(wide_artist_data_zero_one.iloc[query_index, :].reshape(1, -1), n_neighbors = 6)

for i in range(0, len(distances.flatten())):
    if i == 0:
        print ('Recommendations with binary play data for {0}:\n'.format(wide_artist_data_zero_one.index[query_index]))
    else:
        print ('{0}: {1}, with distance of {2}:'.format(i, wide_artist_data_zero_one.index[indices.flatten()[i]], distances.flatten()[i]))

"""Recommending Artists with Fuzzy Matching"""

import string
from fuzzywuzzy import fuzz



def print_artist_recommendations(query_artist, artist_plays_matrix, knn_model, k):
    """
    Inputs:
    query_artist: query artist name
    artist_plays_matrix: artist play count dataframe (not the sparse one, the pandas dataframe)
    knn_model: our previously fitted sklearn knn model
    k: the number of nearest neighbors.
    
    Prints: Artist recommendations for the query artist
    Returns: None
    """
    query_index = None
    ratio_tuples = []
    
    for i in artist_plays_matrix.index:
        ratio = fuzz.ratio(i.lower(), query_artist.lower())
        if ratio >= 75:
            current_query_index = artist_plays_matrix.index.tolist().index(i)
            ratio_tuples.append((i, ratio, current_query_index))
    
    print ('Possible matches: {0}\n'.format([(x[0], x[1]) for x in ratio_tuples]))
    
    try:
        query_index = max(ratio_tuples, key = lambda x: x[1])[2] # get the index of the best artist match in the data
    except:
        print ('Your artist didn\'t match any artists in the data. Try again')
        return None
    
    distances, indices = knn_model.kneighbors(artist_plays_matrix.iloc[query_index, :].reshape(1, -1), n_neighbors = k + 1)

    for i in range(0, len(distances.flatten())):
        if i == 0:
            print ('Recommendations for {0}:\n'.format(artist_plays_matrix.index[query_index]))
        else:
            print ('{0}: {1}, with distance of {2}:'.format(i, artist_plays_matrix.index[indices.flatten()[i]], distances.flatten()[i]))

    return None

print_artist_recommendations('red hot chili peppers', wide_artist_data_zero_one, model_nn_binary, k = 10)

print_artist_recommendations('arctic monkeys', wide_artist_data_zero_one, model_nn_binary, k = 10)

print_artist_recommendations('u2', wide_artist_data_zero_one, model_nn_binary, k = 10)

print_artist_recommendations('dispatch', wide_artist_data_zero_one, model_nn_binary, k = 10)

print_artist_recommendations('pearl jam', wide_artist_data_zero_one, model_nn_binary, k = 10)

print_artist_recommendations('jack johnson', wide_artist_data_zero_one, model_nn_binary, k = 10)

"""**Jaccard**"""

from sklearn.neighbors import NearestNeighbors

model_knn = NearestNeighbors(metric = 'jaccard', algorithm = 'auto')
model_knn.fit(wide_artist_data_sparse)

query_index = np.random.choice(wide_data.shape[0])
print (query_index)
distances, indices = model_knn.kneighbors(wide_artist_data.iloc[query_index, :].reshape(1, -1), n_neighbors = 6)

for i in range(0, len(distances.flatten())):
    if i == 0:
        print ('Recommendations for {0}:\n'.format(wide_artist_data.index[query_index]))
    else:
        print ('{0}: {1}, with distance of {2}:'.format(i, wide_artist_data.index[indices.flatten()[i]], distances.flatten()[i]))

wide_artist_data_zero_one = wide_artist_data.apply(np.sign)
wide_artist_data_zero_one_sparse = csr_matrix(wide_artist_data_zero_one.values)

model_nn_binary = NearestNeighbors(metric='jaccard', algorithm='auto')
model_nn_binary.fit(wide_artist_data_zero_one_sparse)

query_index = np.random.choice(wide_artist_data_zero_one.shape[0])
#print query_index
distances, indices = model_nn_binary.kneighbors(wide_artist_data_zero_one.iloc[query_index, :].reshape(1, -1), n_neighbors = 6)

for i in range(0, len(distances.flatten())):
    if i == 0:
        print ('Recommendations with binary play data for {0}:\n'.format(wide_artist_data_zero_one.index[query_index]))
    else:
        print ('{0}: {1}, with distance of {2}:'.format(i, wide_artist_data_zero_one.index[indices.flatten()[i]], distances.flatten()[i]))

import string
from fuzzywuzzy import fuzz

def print_artist_recommendations(query_artist, artist_plays_matrix, knn_model, k):
    """
    Inputs:
    query_artist: query artist name
    artist_plays_matrix: artist play count dataframe (not the sparse one, the pandas dataframe)
    knn_model: our previously fitted sklearn knn model
    k: the number of nearest neighbors.
    
    Prints: Artist recommendations for the query artist
    Returns: None
    """
    query_index = None
    ratio_tuples = []
    
    for i in artist_plays_matrix.index:
        ratio = fuzz.ratio(i.lower(), query_artist.lower())
        if ratio >= 75:
            current_query_index = artist_plays_matrix.index.tolist().index(i)
            ratio_tuples.append((i, ratio, current_query_index))
    
    print ('Possible matches: {0}\n'.format([(x[0], x[1]) for x in ratio_tuples]))
    
    try:
        query_index = max(ratio_tuples, key = lambda x: x[1])[2] # get the index of the best artist match in the data
    except:
        print ('Your artist didn\'t match any artists in the data. Try again')
        return None
    
    distances, indices = knn_model.kneighbors(artist_plays_matrix.iloc[query_index, :].reshape(1, -1), n_neighbors = k + 1)

    for i in range(0, len(distances.flatten())):
        if i == 0:
            print ('Recommendations for {0}:\n'.format(artist_plays_matrix.index[query_index]))
        else:
            print ('{0}: {1}, with distance of {2}:'.format(i, artist_plays_matrix.index[indices.flatten()[i]], distances.flatten()[i]))

    return None

print_artist_recommendations('red hot chili peppers', wide_artist_data_zero_one, model_nn_binary, k = 10)

print_artist_recommendations('arctic monkeys', wide_artist_data_zero_one, model_nn_binary, k = 10)

print_artist_recommendations('u2', wide_artist_data_zero_one, model_nn_binary, k = 10)

print_artist_recommendations('dispatch', wide_artist_data_zero_one, model_nn_binary, k = 10)

print_artist_recommendations('pearl jam', wide_artist_data_zero_one, model_nn_binary, k = 10)

"""Pearson"""

from sklearn.neighbors import NearestNeighbors

model_knn = NearestNeighbors(metric = 'pearson', algorithm = 'auto')
model_knn.fit(wide_artist_data_sparse)

query_index = np.random.choice(wide_data.shape[0])
print (query_index)
distances, indices = model_knn.kneighbors(wide_artist_data.iloc[query_index, :].reshape(1, -1), n_neighbors = 6)

for i in range(0, len(distances.flatten())):
    if i == 0:
        print ('Recommendations for {0}:\n'.format(wide_artist_data.index[query_index]))
    else:
        print ('{0}: {1}, with distance of {2}:'.format(i, wide_artist_data.index[indices.flatten()[i]], distances.flatten()[i]))

wide_artist_data_zero_one = wide_artist_data.apply(np.sign)
wide_artist_data_zero_one_sparse = csr_matrix(wide_artist_data_zero_one.values)

model_nn_binary = NearestNeighbors(metric='pearson', algorithm='auto')
model_nn_binary.fit(wide_artist_data_zero_one_sparse)

query_index = np.random.choice(wide_artist_data_zero_one.shape[0])
#print query_index
distances, indices = model_nn_binary.kneighbors(wide_artist_data_zero_one.iloc[query_index, :].reshape(1, -1), n_neighbors = 6)

for i in range(0, len(distances.flatten())):
    if i == 0:
        print ('Recommendations with binary play data for {0}:\n'.format(wide_artist_data_zero_one.index[query_index]))
    else:
        print ('{0}: {1}, with distance of {2}:'.format(i, wide_artist_data_zero_one.index[indices.flatten()[i]], distances.flatten()[i]))

import string
from fuzzywuzzy import fuzz

def print_artist_recommendations(query_artist, artist_plays_matrix, knn_model, k):
    """
    Inputs:
    query_artist: query artist name
    artist_plays_matrix: artist play count dataframe (not the sparse one, the pandas dataframe)
    knn_model: our previously fitted sklearn knn model
    k: the number of nearest neighbors.
    
    Prints: Artist recommendations for the query artist
    Returns: None
    """
    query_index = None
    ratio_tuples = []
    
    for i in artist_plays_matrix.index:
        ratio = fuzz.ratio(i.lower(), query_artist.lower())
        if ratio >= 75:
            current_query_index = artist_plays_matrix.index.tolist().index(i)
            ratio_tuples.append((i, ratio, current_query_index))
    
    print ('Possible matches: {0}\n'.format([(x[0], x[1]) for x in ratio_tuples]))
    
    try:
        query_index = max(ratio_tuples, key = lambda x: x[1])[2] # get the index of the best artist match in the data
    except:
        print ('Your artist didn\'t match any artists in the data. Try again')
        return None
    
    distances, indices = knn_model.kneighbors(artist_plays_matrix.iloc[query_index, :].reshape(1, -1), n_neighbors = k + 1)

    for i in range(0, len(distances.flatten())):
        if i == 0:
            print ('Recommendations for {0}:\n'.format(artist_plays_matrix.index[query_index]))
        else:
            print ('{0}: {1}, with distance of {2}:'.format(i, artist_plays_matrix.index[indices.flatten()[i]], distances.flatten()[i]))

    return None

print_artist_recommendations('red hot chili peppers', wide_artist_data_zero_one, model_nn_binary, k = 10)

print_artist_recommendations('arctic monkeys', wide_artist_data_zero_one, model_nn_binary, k = 10)

print_artist_recommendations('u2', wide_artist_data_zero_one, model_nn_binary, k = 10)

print_artist_recommendations('dispatch', wide_artist_data_zero_one, model_nn_binary, k = 10)

